---
title: "Causal Analysis: Firearm Stores Proximity and School Shooting Incidents"
author: "Falco and Michelle"
date: "6/29/2022"
output:
  html_document:
    code_folding: show
---

# Introduction

In the following document we depict the code used to perform the exploratory data analyses and causal analyses for our project on firearm stores proximity and school shooting incidents. This code is stored in a GitHub repository at <https://github.com/NSAPH/firearm_store_proximity_school_shootings>. In the same repository, we stored data to:
1. Perform the data cleaning and data wrangling: `make_datasets.R`,
2. Generate the plots depicted below: `make_usmap.R`.

Feel free to reach out for any question regarding the following code at: <fbargaglistoffi@hsph.harvard.edu> or <michelleqin@college.harvard.edu>.

```{r library_upload, message=FALSE, warning=FALSE, include=TRUE, results='hide', include=FALSE}
# Upload Functions and Packages
rm(list=ls())
library(CausalGPS)
library(MASS)
library(ggplot2)
library(tidyr)
library(pscl)
library(dplyr)
library(SuperLearner)
library(data.table)
```

```{r setup, include=FALSE}
# Set the Working Directory
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE, message = FALSE) # collapse = TRUE allows output to be hidden along with code (by code_folding)
# knitr::opts_knit$set(root.dir = '~/OneDrive - Harvard University/Research/Schools Vs Firearms')
# knitr::opts_knit$set(root.dir = "/Users/s012852/Harvard University/Bargagli Stoffi, Falco Joannes - Schools Vs Firearms/")
```

# Notes from Data Cleaning/Wrangling (make_datasets.R)

We exclude 13 Census tracts from our analysis because they have NA's in the treatment variable (`mean_total_miles`), as well as `min_total_miles` and `max_total_miles`.

We exclude 19 Census tracts with total (residential) population of 0 in 2020.

We exclude 541 Census tracts in Puerto Rico because [The K-12 School Shooting Database](https://www.chds.us/ssdb/) does not cover Puerto Rico.
<!-- also because (i) all of these Census tracts are recorded as having a daytime population of 0 (which is probably wrong?) and (ii) we didn't have a 2013 NCHS urban-rural classification for them, which admittedly we're not currently using in our analysis -->


# Exploratory Data Anaysis

Upload the data.

```{r, message=FALSE, warning=FALSE}
# data <- read.csv("data/all_tracts_2020_subset_vars.csv", header = TRUE, stringsAsFactors = FALSE)
data <- read.csv("~/Harvard University/Bargagli Stoffi, Falco Joannes - Schools Vs Firearms/data/all_tracts_2020_subset_vars.csv", header = TRUE, stringsAsFactors = FALSE)
colnames(data)
dim(data)
```

Check the distribution of Census tract populations (click "See details" below). Observe that (i) There are 19 tracts with total population $<10$; none had shooting incidents; 16 of them have median household income $= 0$. (ii) There are 6 tracts (none of them overlaps with the 19 tracts just mentioned) with daytime population $<10$; none had shooting incidents; 5 of them have median household income $= 0$. Later, we run a sensitivity analysis excluded these low-population tracts.

<details>
  <summary>See details</summary>
```{r}
sum(data$total_population_2020 < 10 & data$daytime_pop_2021 < 10)
hist(data$total_population_2020)
data[data$total_population_2020 < 10, ]
hist(data$daytime_pop_2021)
data[data$daytime_pop_2021 < 10, ]
```
</details> 

The unit of analysis is any Census track with at least one school. The outcome variable is whether there was a shooting (defined as when a gun is brandished, is fired, or a bullet hits school property for any reason, regardless of the number of victims, time of day, or day of week; see justification [here](https://www.chds.us/ssdb/methods/)) between January 2014 and the end of May 2022 in that Census tract. The treatment variable is the average \emph{minimum} walking distance, within a Census tract, between each school and the nearest gun \emph{dealer}.

Additional outcome variables -- such as weapon type, preplanned, targets (i.e., random vs targeted vs both vs neither), school level (i.e., elementary, middle, high, etc.), shooter age -- are available for Census tracts that have had a school shooting since 2014. For the 43 tracts with 2 school shootings and 1 tract with 3 school shootings, these outcome variables are measured for the \emph{most recent} school shooting.

Most confounders are included as a proportion (for instance, of 25+ individuals who have a bachelor's degree) over that Census tract's 2020 population or area in square meters. When possible, however, we use the Census Bureau's calculated proportions, which should be better quality than dividing by 2020 population.

<!-- Several potential confounders (for instance, population of 18+ individuals) are not included in this analysis because they have correlation $>0.83$ with a confounder that is included. The only exception is `pop_below18`, which has a correlation coefficient of 0.871 with `total_population_2020`. -->


```{r}
## Outcome Variable 
y <- data[,c("binary_shooting_incident")]

## Treatment Variable
a <- data[,c("mean_total_km")]
ceiling_a <- ceiling(a)

## Confounders
all_confounder_names <- c("total_population_2020", "housing_units_per_sq_meter",
              "log_median_hh_income", "schools_per_sq_meter", "state_fips", "county_fips",
              "log_median_hh_income_15to24", "total_crime_2021", "dealers_per_sq_meter",
              "daytime_pop_2021", "prop_white_only", "prop_black_only", 
              "prop_asian_only", "prop_multiracial", "prop_hispanic_latino", 
              "prop_food_stamps_2019", "prop_public_assist_income_2019",
              "prop_below_poverty_2019", "prop_without_vehicles_2019",
              "prop_hunted_with_shotgun_2021", "prop_bachelor_deg_25plus_2021", 
              "prop_grad_deg_25plus_2021", "prop_unemployed_2021",
              "prop_unemployed_16to24_2021", "prop_institutional_group",
              "prop_noninstitutional_group", "prop_18plus")
x <- data[, all_confounder_names]
x <- t(apply(x, 1, unlist))

## Generate Analysis Data
data_analysis <- cbind(y, a, as.data.frame(x))
```


Notes about specific confounders:

- To gauge each Census tract's position on the urban/rural continuum, we use population density and housing unit density (over area in square meters).
- `prop_food_stamps_2019`, `prop_public_assist_income_2019`, `prop_below_poverty_2019`, and `prop_without_vehicles_2019` are the American Community Survey (ACS)'s 5-year averages over 2016-2020.
<!-- - In this analysis, we use a variable called "employmentunemployment_unage16cy_p" and call it `prop_unemployed_16to24_2021`. -->
- `prop_multiracial` is the proportion of individuals in that Census tract who identify as 2+ races; these multiracial individuals' specific races are not included in this analysis. (Would it be illogical or strange to try to add a fraction of a person to each of their constituent races?) Click "See details" below.

<details>
  <summary>See details</summary>
```{r, eval=TRUE}
hist(data$prop_multiracial)
summary(data$prop_multiracial)
```
</details>


Confounders we plan to have in subsequent analyses:

- mental health data from Medicaid.


Check the distribution of the treatment (click "See details" below).

<details>
  <summary>See details</summary>
```{r}
quantile(a)
plot(density(a))
plot(density(a[which(a < quantile(a, 0.99))]))
plot(density(a[which(a < quantile(a, 0.95))]))
plot(density(a[which(a < quantile(a, 0.90))]))
```
</details>


<details>
  <summary>Map of school to gun store proximity (in miles) at county level.</summary>
    <!-- ![](/Users/falco/Desktop/figures/counties_map_mean_miles.png) -->
    ![](/Users/s012852/Documents/figures/counties_map_mean_miles.png)
</details>


<details>
  <summary>Map of school to gun store proximity (in miles) at state level.</summary>
    <!-- ![](/Users/falco/Desktop/figures/states_map_mean_miles.png) -->
    ![](/Users/s012852/Documents/figures/states_map_mean_miles.png)
</details>


<details>
  <summary>Map of school to gun store proximity (in miles) at county level (trimming exposures larger than 99th percentile).</summary>
    <!-- ![](/Users/falco/Desktop/figures/counties_map_mean_miles_trimmed99.png) -->
    ![](/Users/s012852/Documents/figures/counties_map_mean_miles_trimmed99.png)
</details>


<details>
  <summary>Map of school to gun store proximity (in miles) at state level (trimming exposures larger than 99th percentile).</summary>
    <!-- ![](/Users/falco/Desktop/figures/states_map_mean_miles_trimmed99.png) -->
    ![](/Users/s012852/Documents/figures/states_map_mean_miles_trimmed99.png)
</details>


<details>
  <summary>Map of school to gun store proximity (in miles) at county level (trimming exposures larger than 95th percentile).</summary>
    <!-- ![](/Users/falco/Desktop/figures/counties_map_mean_miles_trimmed95.png) -->
    ![](/Users/s012852/Documents/figures/counties_map_mean_miles_trimmed95.png)
</details>


<details>
  <summary>Map of school to gun store proximity (in miles) at state level (trimming exposures larger than 95th percentile).</summary>
    <!-- ![](/Users/falco/Desktop/figures/states_map_mean_miles_trimmed95.png) -->
    ![](/Users/s012852/Documents/figures/states_map_mean_miles_trimmed95.png)
</details>


<details>
  <summary>Map of gun dealers per square meter at county level.</summary>
    ![](/Users/s012852/Documents/figures/counties_map_mean_dealers.png)
</details>


<details>
  <summary>Map of gun dealers per square meter at state level.</summary>
    ![](/Users/s012852/Documents/figures/states_map_mean_dealers.png)
</details>


<details>
  <summary>Map of gun dealers per square meter at county level (above median).</summary>
    ![](/Users/s012852/Documents/figures/counties_map_mean_dealers_above_median.png)
</details>


<details>
  <summary>Map of gun dealers per square meter at state level (above median).</summary>
    ![](/Users/s012852/Documents/figures/states_map_mean_dealers_above_median.png)
</details>


<details>
  <summary>Map of gun dealers per square meter at county level (below median).</summary>
    ![](/Users/s012852/Documents/figures/counties_map_mean_dealers_below_median.png)
</details>


<details>
  <summary>Map of gun dealers per square meter at state level (below median).</summary>
    ![](/Users/s012852/Documents/figures/states_map_mean_dealers_below_median.png)
</details>

## Some interesting cases

```{r, echo=F, message=F}
dt <- as.data.table(data)
```

Year/Month of school shootings:

```{r}
library(lubridate)

Date <- as.Date(dt[binary_shooting_incident == 1, Date])
hist(year(Date))
hist(month(Date), breaks = 12)
sum(is.na(Date))
```

Time of shooting:

```{r}
time <- dt[!Time_Period %in% c("", "null"), Time_Period]
length(time)
table(time)
```

Shooter ages:

```{r}
# incidents where exact shooter age is known
shooter_age_integer <- dt[binary_shooting_incident == 1 & !shooter_age %in% c("Adult", "Child", "Minor", "Teen", "null"), .(count_school_shootings, Date, shooter_age = as.integer(shooter_age), Narrative, Summary, Situation, Targets)]
shooter_age_integer <- shooter_age_integer[!is.na(shooter_age)]
nrow(shooter_age_integer)
summary(shooter_age_integer$shooter_age)
hist(shooter_age_integer$shooter_age)

# incidents where shooter age is categorized (exact age unknown)
shooter_age_categorical <- dt[binary_shooting_incident == 1 & shooter_age %in% c("Adult", "Child", "Minor", "Teen"), shooter_age]
table(shooter_age_categorical)

# extreme ages
shooter_age_integer[shooter_age < 10]
shooter_age_integer[shooter_age > 70]
```

School level of shootings:

```{r}
school_level <- dt[!School_Level %in% c("", "null", "Unknown"), School_Level]
length(school_level)
table(school_level)
```

Accidental school shootings:

```{r}
library(stringr)
    
accidents <- dt[binary_shooting_incident == 1 & str_detect(Situation, "Accident"),
                       .(count_school_shootings, Date, Preplanned, Narrative, Situation, Targets)]
nrow(accidents)
accidents[1:10,]
```

Shootings off school property:

```{r}
off_property <- as.data.table(data)[binary_shooting_incident == 1 & Location_Type == "Off School Property",
                             .(count_school_shootings, Date, Location, Location_Type, Narrative, Summary, Situation)]
nrow(off_property)
off_property[1:10, ]
```


# Exploratory Data Analysis

Run a logistic regression to explore the associations between the treatment and the outcome controlling for all the confounders.

```{r, message=FALSE}
# Logistic Regression (unrestricted a, 57793 observations)
logistic_model <- glm(y ~ a + x, 
                      data = data_analysis, 
                      family = "binomial")
summary(logistic_model)
```

Run a negative binomial regression to explore the associations between the treatment and the outcome controlling for all the confounders.

```{r, message=FALSE}
# Negative Binomial
negative_binomial <- glm.nb(y ~ a + x, data = data_analysis)
summary(negative_binomial)

# Zero Inflated Negative Binomial
zinb <- zeroinfl(y ~ a | a ,
                 dist = "negbin", data = data_analysis)
summary(zinb)
```

```{r}
dat <- table(ceiling_a, data_analysis$y)
events <- dat[,2]
denominator <- dat[,1]
dat <- cbind(events, denominator, events/(events + denominator))
dat
```


# Causal Analysis with Generalized Propensity Score (GPS) matching

First, we write a few functions, which we will use to perform all our GPS-matching causal analyses (i.e., both the main analysis and several sensitivity analyses where we exclude certain variables and/or observations).

In particular, for each analysis we run, we will output (i) the covariate balance plot, (ii) the results of a logistic regression model on the GPS-matched "pseudo-population", and (iii) the results of a nonparametric model on the GPS-matched data, which uses a local polynomial kernel regression.

```{r, message=FALSE}
get_matched_pseudo_pop <- function(outcome, exposure, confounders, trim_quantiles = c(0.05, 0.95)){
  return(generate_pseudo_pop(Y = outcome,
                             w = exposure,
                             c = as.data.frame(confounders),
                             ci_appr = "matching",
                             pred_model = "sl",
                             gps_model = "parametric",
                             use_cov_transform = TRUE,
                             transformers = list("pow2", "pow3"),
                             sl_lib = c("m_xgboost"),
                             params = list(xgb_nrounds = c(50)),
                             nthread = 4,
                             covar_bl_method = "absolute",
                             covar_bl_trs = 0.1,
                             covar_bl_trs_type = "mean",
                             trim_quantiles = trim_quantiles, 
                             optimized_compile = TRUE, 
                             max_attempt = 5,
                             matching_fun = "matching_l1",
                             delta_n = 0.2,
                             scale = 1.0))
}

make_matched_correlation_plot <- function(matched_pop, exposure, confounders, confounder_names){
  # get correlations of matched and unmatched data
  cor_val_matched <- matched_pop$adjusted_corr_results
  cor_val_unmatched <- matched_pop$original_corr_results
  
  # gather correlations into 1 data frame
  abs_cor = data.frame(cov = confounder_names,
                       unmatched = cor_val_unmatched$absolute_corr,
                       matched = cor_val_matched$absolute_corr) %>%
    gather(c(unmatched, matched), key = 'dataset', value = 'absolute correlation')
  
  # make plot
  p <- ggplot(abs_cor, aes(x = cov, y = `absolute correlation`, color = dataset, group = dataset)) +
    geom_point() +
    geom_line() +
    theme(axis.text.x = element_text(angle = 90))
  
  return(p)
}

get_matched_logistic_results <- function(matched_pop){
  pseudo <- matched_pop$pseudo_pop
  outcome <- estimate_pmetric_erf(formula = Y ~ w,
                                  family = binomial,
                                  data = pseudo,
                                  ci_appr = "matching")
  return(summary(outcome))
}

get_matched_nonparametric_results <- function(matched_pop){
  pseudo <- matched_pop$pseudo_pop
  erf_obj <- estimate_npmetric_erf(as.double(pseudo$Y),
                                           as.double(pseudo$w),
                                           bw_seq=seq(0.2,2,0.2),
                                           w_vals = seq(0,15,0.5),
                                           nthread = 1)

  return(plot(erf_obj))
}
```

## Main Analysis 

For our main causal analysis, we use GPS matching to re-balance our data and guarantee a fair comparison between treated and control units. In particular, to guarantee the highest similarity between treated and control units, we implement a trimming procedure for the GPS at the 5th/95th percentiles and the exposure at the 95th percentile. Indeed, for units below/above the 5th/95th GPS percentiles and with exposure above the 95th percent, it would be very hard to find a "twin" observation for them to be compared to.

```{r}
set.seed(2021)
```

```{r, message=FALSE}
data_analysis_trim_exposure <- data_analysis[which(a < quantile(a, 0.95)),]

matched_pop_trim <- get_matched_pseudo_pop(data_analysis_trim_exposure$y, data_analysis_trim_exposure$a, data_analysis_trim_exposure[, all_confounder_names])
make_matched_correlation_plot(matched_pop_trim, data_analysis_trim_exposure$a, data_analysis_trim_exposure[, all_confounder_names], all_confounder_names)
get_matched_logistic_results(matched_pop_trim)
get_matched_nonparametric_results(matched_pop_trim)
```


# Robustness Checks

## More Lenient Trimming, One-Sided Trimming, and No Exposure Trimming

Our first robustness check is to trim the GPS tails at the 1st/99th percentiles of GPS (and maintain the trimming of the exposure at the 95th percentile).

Observe that the results are quite different from the main analysis.

```{r, message=FALSE}
matched_pop_trim_gps99 <- get_matched_pseudo_pop(data_analysis_trim_exposure$y, data_analysis_trim_exposure$a, data_analysis_trim_exposure[, all_confounder_names], c(0.01, 0.99))
make_matched_correlation_plot(matched_pop_trim_gps99, data_analysis_trim_exposure$a, data_analysis_trim_exposure[, all_confounder_names], all_confounder_names)
get_matched_logistic_results(matched_pop_trim_gps99)
get_matched_nonparametric_results(matched_pop_trim_gps99)
```

Our second robustness check is to trim the GPS only at the 95th percentile (and maintain the trimming of the exposure at the 95th percentile).

```{r, message=FALSE}
matched_pop_trim_gps95_onesided <- get_matched_pseudo_pop(data_analysis_trim_exposure$y, data_analysis_trim_exposure$a, data_analysis_trim_exposure[, all_confounder_names], trim = c(0, 0.95))
make_matched_correlation_plot(matched_pop_trim_gps95_onesided, data_analysis_trim_exposure$a, data_analysis_trim_exposure[, all_confounder_names], all_confounder_names)
get_matched_logistic_results(matched_pop_trim_gps95_onesided)
get_matched_nonparametric_results(matched_pop_trim_gps95_onesided)
```

Next, we trim the GPS at the 5th/95th percentiles (as in the main analysis) but do not trim the exposure.

```{r, message=FALSE}
matched_pop_exposure_untrimmed <- get_matched_pseudo_pop(y, a, x)
make_matched_correlation_plot(matched_pop_exposure_untrimmed, a, x, all_confounder_names)
get_matched_logistic_results(matched_pop_exposure_untrimmed)
get_matched_nonparametric_results(matched_pop_exposure_untrimmed)
```

## Different Definition of the Treatment (Ceiling)

Now, we define the treatment variable as the ceiling of a. In this way, the group all the treated units within a 1, 2, 3, 4, .. km average distance between school and gun stores.

Observe that the results are quite different from the main analysis -- nor is covariate balance achieved.

```{r, message=FALSE}
data_analysis_within_distance <- cbind(y, ceiling_a, as.data.frame(x))

matched_pop_within_distance <- get_matched_pseudo_pop(y, ceiling_a, x)
make_matched_correlation_plot(matched_pop_within_distance, ceiling_a, x, all_confounder_names)
get_matched_logistic_results(matched_pop_within_distance)
get_matched_nonparametric_results(matched_pop_within_distance)
```


## Discretizing the Treatment Variable

We again trim the GPS at the 5th/95th percentiles but discretize treatment into $[0,2), [2, 4)$, and 4 or more km. Code treatment levels as 0, 1, 2.

```{r, message=FALSE}
data_discretized <- data_analysis
data_discretized$a <- ifelse(a < 2, 0, ifelse(a < 4, 1, 2))

matched_pop_discretized_treatment <- get_matched_pseudo_pop(y, data_discretized$a, x)
make_matched_correlation_plot(matched_pop_discretized_treatment, data_discretized$a, x, all_confounder_names)
get_matched_logistic_results(matched_pop_discretized_treatment)
get_matched_nonparametric_results(matched_pop_discretized_treatment)
```


## Excluding 2021 Total Crime Index

We run the same analysis (trimming the GPS at the 5th/95th percentiles and the exposure at the 95th percentile) but excluding `total_crime_2021` as a confounder.

```{r, message=FALSE}
confounders_without_crime2021 <- all_confounder_names[all_confounder_names != "total_crime_2021"]

matched_pop_without_crime2021 <- get_matched_pseudo_pop(data_analysis_trim_exposure$y, data_analysis_trim_exposure$a, data_analysis_trim_exposure[, confounders_without_crime2021])
make_matched_correlation_plot(matched_pop_without_crime2021, data_analysis_trim_exposure$a, data_analysis_trim_exposure[, confounders_without_crime2021], confounders_without_crime2021)
get_matched_logistic_results(matched_pop_without_crime2021)
get_matched_nonparametric_results(matched_pop_without_crime2021)
```


## Excluding Firearm Stores Density

We run the same analysis (trimming the GPS at the 5th/95th percentiles and the exposure at the 95th percentile) but excluding `dealers_per_sq_meter` as a confounder.

Observe that the results are quite different from the main analysis.

```{r, message=FALSE}
confounders_without_dealers <- all_confounder_names[all_confounder_names != "dealers_per_sq_meter"]

matched_pop_without_dealers <- get_matched_pseudo_pop(data_analysis_trim_exposure$y, data_analysis_trim_exposure$a, data_analysis_trim_exposure[, confounders_without_dealers])
make_matched_correlation_plot(matched_pop_without_dealers, data_analysis_trim_exposure$a, data_analysis_trim_exposure[, confounders_without_dealers], confounders_without_dealers)
get_matched_logistic_results(matched_pop_without_dealers)
get_matched_nonparametric_results(matched_pop_without_dealers)
```


## Excluding Race Confounders

We run the same analysis (trimming the GPS at the 5th/95th percentiles and the exposure at the 95th percentile) but excluding all 5 race confounders, which are measured as Census-tract-level proportions.

```{r, message=FALSE}
race_confounders <- c("prop_white_only", "prop_black_only", "prop_asian_only", "prop_multiracial", "prop_hispanic_latino")
confounders_without_race <- all_confounder_names[!all_confounder_names %in% race_confounders]

matched_pop_without_race <- get_matched_pseudo_pop(data_analysis_trim_exposure$y, data_analysis_trim_exposure$a, data_analysis_trim_exposure[, confounders_without_race])
make_matched_correlation_plot(matched_pop_without_race, data_analysis_trim_exposure$a, data_analysis_trim_exposure[, confounders_without_race], confounders_without_race)
get_matched_logistic_results(matched_pop_without_race)
get_matched_nonparametric_results(matched_pop_without_race)
```


## Excluding Small Census Tracts

We run the same analysis (trimming the GPS at the 5th/95th percentiles and the exposure at the 95th percentile) but excluding Census tracts with total population or daytime population less than 10.

Observe that the results are quite different from the main analysis.

```{r, message=FALSE}
data_exclude_small_tracts <- data_analysis[data_analysis$total_population_2020 >= 10 & data_analysis$daytime_pop_2021 >= 10, ]
data_exclude_small_tracts <- data_exclude_small_tracts[which(data_exclude_small_tracts$a < quantile(data_exclude_small_tracts$a, 0.95)),] # trim exposure at 95th percentile

matched_exclude_small_tracts <- get_matched_pseudo_pop(data_exclude_small_tracts$y, data_exclude_small_tracts$a, data_exclude_small_tracts[, all_confounder_names])
make_matched_correlation_plot(matched_exclude_small_tracts, data_exclude_small_tracts$a, data_exclude_small_tracts[, all_confounder_names], all_confounder_names)
get_matched_logistic_results(matched_exclude_small_tracts)
get_matched_nonparametric_results(matched_exclude_small_tracts)
```


## Changing the Seed

We run the same analysis (trimming the GPS at the 5th/95th percentiles and the exposure at the 95th percentile) but using a different seed (2022 instead of 2021).

```{r}
set.seed(2022)
```

```{r, message=FALSE}
matched_pop_trim_seed2 <- get_matched_pseudo_pop(data_analysis_trim_exposure$y, data_analysis_trim_exposure$a, data_analysis_trim_exposure[, all_confounder_names])
make_matched_correlation_plot(matched_pop_trim_seed2, data_analysis_trim_exposure$a, data_analysis_trim_exposure[, all_confounder_names], all_confounder_names)
get_matched_logistic_results(matched_pop_trim_seed2)
get_matched_nonparametric_results(matched_pop_trim_seed2)
```


# Stratified analysis

We include only Census tracts with gun dealer density [less than or] equal to the median gun dealer density, which is 0. That is, we include only Census tracts that themselves \emph{do not} contain a gun dealer. This leaves 28,485 Census tracts to analyze. Then, we run the same analysis (trimming the GPS at the 5th/95th percentiles and the exposure at the 95th percentile).

```{r}
data_dealers_below_median <- data_analysis[data_analysis$dealers_per_sq_meter <= 0, ]
data_dealers_below_median <- data_dealers_below_median[which(data_dealers_below_median$a < quantile(data_dealers_below_median$a, 0.95)),] # after subsetting to below-median-dealer-density, trim exposures at 95th percentile
nrow(data_dealers_below_median)

matched_pop_dealers_below_median <- get_matched_pseudo_pop(data_dealers_below_median$y, data_dealers_below_median$a, data_dealers_below_median[, all_confounder_names])
make_matched_correlation_plot(matched_pop_dealers_below_median, data_dealers_below_median$a, data_dealers_below_median[, all_confounder_names], all_confounder_names)
get_matched_logistic_results(matched_pop_dealers_below_median)
get_matched_nonparametric_results(matched_pop_dealers_below_median)
```


Next, we include only Census tracts with gun dealer density greater than the median gun dealer density, which is 0. That is, we include only Census tracts that themselves \emph{do} contain a gun dealer. This leaves 25,903 Census tracts to analyze. Then, we run the same analysis (trimming the GPS at the 5th/95th percentiles and the exposure at the 95th percentile).

```{r}
data_dealers_above_median <- data_analysis[data_analysis$dealers_per_sq_meter > 0, ]
data_dealers_above_median <- data_dealers_above_median[which(data_dealers_above_median$a < quantile(data_dealers_above_median$a, 0.95)),]
nrow(data_dealers_above_median)

matched_pop_dealers_above_median <- get_matched_pseudo_pop(data_dealers_above_median$y, data_dealers_above_median$a, data_dealers_above_median[, all_confounder_names])
make_matched_correlation_plot(matched_pop_dealers_above_median, data_dealers_above_median$a, data_dealers_above_median[, all_confounder_names], all_confounder_names)
get_matched_logistic_results(matched_pop_dealers_above_median)
get_matched_nonparametric_results(matched_pop_dealers_above_median)
```


# Next Steps

- Finalize which variables to use.
- More sensitivity analyses.
- Run the analysis using weighting.
- Explore other outcomes: weapon type, preplanned, targets (i.e., random vs targeted vs both vs neither), school level (i.e., elementary, middle, high, etc.), number of shots fired, shooter age.
- Double-check code.

